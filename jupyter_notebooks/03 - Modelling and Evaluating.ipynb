{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluating**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "* Train and validate a CNN-based classifier to distinguish healthy vs. powdery-mildew leaves.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* `input/datasets/cherry_leaf_dataset/cherry-leaves/train`\n",
        "* `input/datasets/cherry_leaf_dataset/cherry-leaves/validation`\n",
        "* `input/datasets/cherry_leaf_dataset/cherry-leaves/test`\n",
        "* `image_shape = (256, 256, 3)` embedding from Notebook 2\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Data‐loading & augmentation pipeline  \n",
        "* Model architecture definition and compilation  \n",
        "* Trained model saved to `models/cherry_leaf_classifier.h5`  \n",
        "* Learning‐curve plot (`figures/learning_curves.png`)  \n",
        "* Confusion‐matrix plot on test set (`figures/confusion_matrix.png`)  \n",
        "* Classification report (printed and saved as `reports/classification_report.txt`)  \n",
        "* Sample prediction function and example inference on a random image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "from matplotlib.image import imread\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We update the working directory as in the previous notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/PP5-MildewDetection/jupyter_notebooks'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspaces/PP5-MildewDetection'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Set Train, Validation and Test Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'input/datasets/cherry_leaf_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all figures into: outputs/v1/figures\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# versioning & output directory\n",
        "version = \"v1\"\n",
        "base_out = Path(\"outputs\") / version\n",
        "figures_out = base_out / \"figures\"\n",
        "\n",
        "# create folders if they don’t exist\n",
        "figures_out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Saving all figures into: {figures_out}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels: ['healthy', 'powdery_mildew']\n"
          ]
        }
      ],
      "source": [
        "labels = sorted(\n",
        "    [p.name for p in Path(train_path).iterdir() if p.is_dir()]\n",
        ")\n",
        "print(\"Labels:\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Image Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shape aligned with the distribution identified in Notebook 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using image_shape: (256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "image_shape = (256, 256, 3)\n",
        "print(\"Using image_shape:\", image_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Initial Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch_size=32, learning_rate=0.001, epochs=10\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "print(f\"batch_size={batch_size}, learning_rate={learning_rate}, epochs={epochs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Preparation & Augmentation\n",
        "\n",
        "- Rescale all images from [0–255] to [0–1].  \n",
        "- Augment training images with random transforms (rotation, zoom, flip) to reduce overfitting.  \n",
        "- Batch and shuffle the data for efficient training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-24 14:30:44.963718: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-24 14:30:45.967367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2944 images belonging to 2 classes.\n",
            "Found 420 images belonging to 2 classes.\n",
            "Found 844 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define augmenting generator\n",
        "train_gen = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Non-augmenting generators for validation/test\n",
        "test_val_gen = ImageDataGenerator(rescale=1/255.0)\n",
        "\n",
        "# Create iterators\n",
        "train_iterator = train_gen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_iterator = test_val_gen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_iterator = test_val_gen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=image_shape[:2],\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Prep Conclusion\n",
        "\n",
        "We’ve established our data pipelines: \n",
        "- Training images are rescaled and augmented to improve generalisation.  \n",
        "- Validation/Test images are only rescaled to ensure fair performance evaluation.  \n",
        "\n",
        "These iterators feed directly into model training and evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "    # create here your folder\n",
        "    # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
