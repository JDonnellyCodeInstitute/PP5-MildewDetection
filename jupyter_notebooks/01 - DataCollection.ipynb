{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch cherry leaf image data from Kaggle and prepare it for use.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - authentication token. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Dataset: input/datasets/cherry_leaf_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r /workspaces/PP5-MildewDetection/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will store the notebooks in a subfolder, therefore when running the notebook in the editor, we need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaggle Installation and Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we install Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cell below changes the Kaggle configuration directory to the current working directory and sets permissions for the Kaggle authentication JSON."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we set the Kaggle dataset path and download it to the folder we specified in the 'Outputs' section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = \"codeinstitute/cherry-leaves\"\n",
        "DestinationFolder = \"input/datasets/cherry_leaf_dataset\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we unzip the downloaded file then delete the zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/cherry-leaves.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The below method allows us to find and remove files of a particular extension type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def clean_image_dataset(root_dir, extensions=None):\n",
        "    \"\"\"\n",
        "    Remove any files in each subdirectory of root_dir whose suffix\n",
        "    is not in the allowed extensions, and print a summary.\n",
        "    \"\"\"\n",
        "    # Default to common image suffixes if none are provided\n",
        "    allowed = {'.png', '.jpg', '.jpeg'} if extensions is None else set(ext.lower() for ext in extensions)\n",
        "    root = Path(root_dir)\n",
        "\n",
        "    for subfolder in root.iterdir():\n",
        "        if not subfolder.is_dir():\n",
        "            continue  # skip files at the top level\n",
        "\n",
        "        kept, removed = 0, 0\n",
        "        for file in subfolder.iterdir():\n",
        "            # Only consider actual files\n",
        "            if not file.is_file():\n",
        "                continue\n",
        "\n",
        "            if file.suffix.lower() in allowed:\n",
        "                kept += 1\n",
        "            else:\n",
        "                file.unlink()   # delete non-image file\n",
        "                removed += 1\n",
        "\n",
        "        print(f\"Subfolder '{subfolder.name}': kept {kept} images, removed {removed} non-images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to find and remove any non-image files from our dataset, if they exist.\n",
        "\n",
        "We create a variable and assign it the pathway to our data which will be the 'root_dir' parameter of the clean_image_dataset method.\n",
        "\n",
        "As we are looking for image files the 'extensions' parameter does not need to be altered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_path = \"input/datasets/cherry_leaf_dataset/cherry-leaves\"\n",
        "clean_image_dataset(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Splitting Train, Validation and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def split_dataset(data_dir, train_ratio, val_ratio, test_ratio):\n",
        "    \"\"\"\n",
        "    Split each classâ€‘folder under data_dir into train/validation/test\n",
        "    according to the three ratios (which must add to 1.0).\n",
        "    \"\"\"\n",
        "    # Validate ratios sum to 1\n",
        "    if train_ratio + val_ratio + test_ratio != 1.0:\n",
        "        print(\"Error: train_ratio + val_ratio + test_ratio must equal 1.0\")\n",
        "        return\n",
        "\n",
        "    # Find class folders skipping any existing split directories\n",
        "    classes = [\n",
        "        d for d in os.listdir(data_dir)\n",
        "        if os.path.isdir(os.path.join(data_dir, d))\n",
        "           and d not in ('train', 'validation', 'test')\n",
        "    ]\n",
        "\n",
        "    # Create train/validation/test subfolders for each class\n",
        "    for split in ('train', 'validation', 'test'):\n",
        "        for cls in classes:\n",
        "            os.makedirs(os.path.join(data_dir, split, cls), exist_ok=True)\n",
        "\n",
        "    # Shuffle and move\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(data_dir, cls)\n",
        "        files = os.listdir(cls_path)\n",
        "        random.shuffle(files)\n",
        "\n",
        "        total = len(files)\n",
        "        n_train = int(total * train_ratio)\n",
        "        n_val   = int(total * val_ratio)\n",
        "        n_test  = int(total * test_ratio)\n",
        "\n",
        "        for i, fname in enumerate(files):\n",
        "            src = os.path.join(cls_path, fname)\n",
        "\n",
        "            if i < n_train:\n",
        "                split = 'train'\n",
        "            elif i < n_train + n_val:\n",
        "                split = 'validation'\n",
        "            elif i < n_train + n_val + n_test:\n",
        "                split = 'test'\n",
        "            else:\n",
        "                # In case of any rounding leftovers, put them in 'test'\n",
        "                split = 'test'\n",
        "\n",
        "            dst = os.path.join(data_dir, split, cls, fname)\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "        # Remove empty original folder\n",
        "        os.rmdir(cls_path)\n",
        "\n",
        "        # Feedback exact counts\n",
        "        print(f\"Class '{cls}': train={n_train}, validation={n_val}, test={n_test}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In keeping with convention:\n",
        "\n",
        "* We will allocate 70% of the data to Training.\n",
        "* 10% to Validation.\n",
        "* 20% to Testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_dataset(\n",
        "    data_dir=\"input/datasets/cherry_leaf_dataset/cherry-leaves\",\n",
        "    train_ratio=0.7,\n",
        "    val_ratio=0.1,\n",
        "    test_ratio=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "3.12.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
